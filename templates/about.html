<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - ToxicTweet-Tagger</title>
    <link rel="stylesheet" type="text/css" href="/static/style.css">
</head>

<body>
    <header class="header">
        <div class="project_name">
            <h4>Subinoy Bera : ToxicTweet-Tagger</h4>
        </div>
        <nav class="nav-links">
            <a href="/">Home</a>
            <a href="/about">About</a>
        </nav>
    </header>

    <div class="about_container">
        <section class="about_content">
            <h1 style="text-align: center;"><u>End to End Hate Tweet Detection Application</u></h1>
            <p>
                Unlike <b>typical ML Demos or AI Wrappers</b>, where you see calling an OpenAI/Gemini API and showing the respose, or coming up with just another prediction model having some fancy accuracy, - this project stands out to mimic <b>real-world production grade workflows.</b> üî•‚úÖ<br> <i>"The real engineering, is not in the model performance but its in the overall system's performance"</i> is what being showcased. It covers the <b>complete lifecycle</b> of an ML solution from developing <b>core ML pipeline</b>, implementation of <b>MLOps</b>, creating <b>inference API</b>, which includes <b>automated testing, deployment</b> and <b>serving</b> with <b>CI/CD</b> - following industry best practices for <b>scalibility</b>, <b>reproducibility</b> and <b>maintainablity</b>.
            </p>
            <br>
            <p>
                üìä <b>ML Pipeline</b>: Fully modular and reproducible ML pipeline designed in a clean, scalable structure. Used DVC for data and pipeline tracking & version control.<br> 
                ‚öôÔ∏è <b>MLOps Tools</b>: Experiments tracking, model versioning and registration with Mlflow. Automated testing with Tox configuration, Github Actions for CI/CD pipeline automation and deployment, Evidently for checking data drift, etc ..<br> 
                ‚ö° <b>Model Serving</b>: Model inferencing through RESTful API for high performance and real-time predictions. Deployed on HuggingFace Spaces for accessible model serving.
                <br>
                <br>
                üìå <b>Note</b>: Used LIME for model observability, which increased inference time to ~ 4.5secs when deployed! Performed optimization and redeployed, reducing inference time to ~ 0.3-0.6 secs. Still it can be have latency issues and cold start delays. <b>All open source tools and free services have been used to make this application!</b> <br> 
            </p>
            <br>

            <p>üí° For more info - please visit <a href="https://github.com/SubinoyBera/Toxic-TweetTagger">Github</a> ‚ÜóÔ∏è</p>
            <p> üíñ THANK YOU : <i>with love and regards from Subinoy (developer)</i> üôè</p>
    <div>

    <footer class="footer">
        <p>&copy; 2025 Subinoy Bera. All rights reserved.</p>
    </footer>
</body>
</html>
