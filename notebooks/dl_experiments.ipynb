{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ddfb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retweet to the rejects who constantly call my ...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i purpose that whatever attack everyone who ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>are you fucking kidding me you deserve to fuck...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Label  num_words\n",
       "0  retweet to the rejects who constantly call my ...      1         24\n",
       "1  i purpose that whatever attack everyone who ca...      1         16\n",
       "2  are you fucking kidding me you deserve to fuck...      1         10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"artifacts/final_data.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c55a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   Content    120000 non-null  object\n",
      " 1   Label      120000 non-null  int64 \n",
      " 2   num_words  120000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ed7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatization(text):\n",
    "    lemmtizer = WordNetLemmatizer()\n",
    "    text_words = text.split()\n",
    "    text = [lemmtizer.lemmatize(word) for word in text_words]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "df['Content'] = df['Content'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91463495",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 7000\n",
    "max_seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7d249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_vocab, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd7b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7db196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq = pad_sequences(sequences, maxlen=max_seq_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589f49b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3,  256,   18, ...,  164,   40,   16],\n",
       "       [ 318,  977,    0, ...,    0,    0,    0],\n",
       "       [   1,  236,   45, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  43,  108,   41, ...,    0,    0,    0],\n",
       "       [ 181,   23, 1089, ...,   22,  145,    1],\n",
       "       [  49,   12, 1516, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c51865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = padded_seq\n",
    "y = df['Label'].values\n",
    "\n",
    "X1, X_test, y1, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X1, y1, test_size=0.1/0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d8ca72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96000, 100), (12000, 100))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d596452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e21b2051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66595"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d920b3c",
   "metadata": {},
   "source": [
    "#### Training LSTM model - v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_seq_len, mask_zero=True),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    LSTM(32,return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=6,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b620e",
   "metadata": {},
   "source": [
    "#### Training LSTM model - v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, LayerNormalization, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=max_seq_len, mask_zero=True),\n",
    "    LSTM(16, return_sequences=True),\n",
    "    LayerNormalization(),\n",
    "    LSTM(8, dropout=0.2, recurrent_dropout=0.2 ,return_sequences=False),\n",
    "    LayerNormalization(),\n",
    "    Dense(8, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c41d28b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 64)           4262080   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 16)           5184      \n",
      "                                                                 \n",
      " layer_normalization (Layer  (None, 100, 16)           32        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 8)                 800       \n",
      "                                                                 \n",
      " layer_normalization_1 (Lay  (None, 8)                 16        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 8)                 32        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4268225 (16.28 MB)\n",
      "Trainable params: 4268209 (16.28 MB)\n",
      "Non-trainable params: 16 (64.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2439c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='models/lstm-v2.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edb3f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beefcbaa",
   "metadata": {},
   "source": [
    "#### Training Bi-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Embedding, Bidirectional, LSTM, Dense,\n",
    "                                     Dropout, BatchNormalization, GlobalMaxPooling1D)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=max_seq_len, mask_zero=True),\n",
    "    Bidirectional(LSTM(16, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e988908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 64)           4262080   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 100, 32)           10368     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Gl  (None, 32)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4273057 (16.30 MB)\n",
      "Trainable params: 4273025 (16.30 MB)\n",
      "Non-trainable params: 32 (128.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92a27e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback1 = ModelCheckpoint(\n",
    "    filepath='models/bilstm.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint_callback1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving tokenizer\n",
    "import pickle\n",
    "pickle.dump(tokenizer, open('models/tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a64c8",
   "metadata": {},
   "source": [
    "### Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72459c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"artifacts/final_data.csv\")\n",
    "df.drop(columns='Content_int', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4bd2008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    174\n",
       "1     26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df.sample(n=200, random_state=60)\n",
    "\n",
    "test_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d34ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Content    0\n",
       "Label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "621b67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Removing Stopwords from texts\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(text)\n",
    "\n",
    "# Lemmatizing words\n",
    "def lemmatization(text):\n",
    "    lemmtizer = WordNetLemmatizer()\n",
    "    text_words = text.split()\n",
    "    text = [lemmtizer.lemmatize(word) for word in text_words]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "# Preprocessing function\n",
    "from tqdm import tqdm\n",
    "def preprocess(df):\n",
    "    try:\n",
    "        tqdm.pandas()\n",
    "        print(\"Removing stopwords...\")\n",
    "        df['Content'] = df['Content'].progress_apply(remove_stopwords)\n",
    "        \n",
    "        print(\"\\n Performing lemmatization\")\n",
    "        df['Content'] = df['Content'].progress_apply(lemmatization)\n",
    "\n",
    "        print(\"\\n Finished preprocessing successfully\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "409a5887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing stopwords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 1054.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Performing lemmatization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 32.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Finished preprocessing successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237813</th>\n",
       "      <td>white council see remove stuff white counsil a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202190</th>\n",
       "      <td>result terror result violence result demonstra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423720</th>\n",
       "      <td>utc concerned edits mirach didnt bother correc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338957</th>\n",
       "      <td>even wikipedia agrees</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136158</th>\n",
       "      <td>retweet ferguson crisis slut manufactured open...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content Label\n",
       "237813  white council see remove stuff white counsil a...     0\n",
       "202190  result terror result violence result demonstra...     0\n",
       "423720  utc concerned edits mirach didnt bother correc...     0\n",
       "338957                              even wikipedia agrees     0\n",
       "136158  retweet ferguson crisis slut manufactured open...     1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_testdf = preprocess(test_df)\n",
    "norm_testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8364a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = tokenizer.texts_to_sequences(test_df['Content'])\n",
    "X1_padded_test = pad_sequences(X1_test, maxlen=max_seq_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e52924",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test = test_df['Label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24446b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model paths\n",
    "bilstm_model_path = \"models/bi-lstm.h5\"\n",
    "lstmv1_model_path = \"models/lstm-v1.h5\"\n",
    "lstmv2_model_path = \"models/lstm-v2.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "bilstm = load_model(bilstm_model_path)\n",
    "lstmv1 = load_model(lstmv1_model_path)\n",
    "lstmv2 = load_model(lstmv2_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b48d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed692d9",
   "metadata": {},
   "source": [
    "#### RESULTS ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 69ms/step\n",
      "accuracy:  0.79\n",
      "precision:  0.3620689655172414\n",
      "recall:  0.8076923076923077\n",
      "roc_auc:  0.7975243147656941\n"
     ]
    }
   ],
   "source": [
    "# testing bilstm model\n",
    "\n",
    "y_prob = bilstm.predict(X1_padded_test)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(y1_test, y_pred))\n",
    "print(\"precision: \", precision_score(y1_test, y_pred))\n",
    "print(\"recall: \", recall_score(y1_test, y_pred))\n",
    "print(\"roc_auc: \", roc_auc_score(y1_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 23ms/step\n",
      "accuracy:  0.76\n",
      "precision:  0.328125\n",
      "recall:  0.8076923076923077\n",
      "roc_auc:  0.7802829354553493\n"
     ]
    }
   ],
   "source": [
    "# testing lstm-v1 model\n",
    "\n",
    "y_prob = lstmv1.predict(X1_padded_test)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(y1_test, y_pred))\n",
    "print(\"precision: \", precision_score(y1_test, y_pred))\n",
    "print(\"recall: \", recall_score(y1_test, y_pred))\n",
    "print(\"roc_auc: \", roc_auc_score(y1_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ccfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 21ms/step\n",
      "accuracy:  0.82\n",
      "precision:  0.4074074074074074\n",
      "recall:  0.8461538461538461\n",
      "roc_auc:  0.8311229000884174\n"
     ]
    }
   ],
   "source": [
    "# testing lstm-v2 model\n",
    "\n",
    "y_prob = lstmv2.predict(X1_padded_test)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(y1_test, y_pred))\n",
    "print(\"precision: \", precision_score(y1_test, y_pred))\n",
    "print(\"recall: \", recall_score(y1_test, y_pred))\n",
    "print(\"roc_auc: \", roc_auc_score(y1_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
